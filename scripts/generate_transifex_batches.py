#!/usr/bin/env python3
"""
Generate optimal batch configuration for Transifex translation uploads.

This script creates GitHub Actions matrix configuration to prevent API overload
by grouping locales into manageable batches with controlled parallelism.

Usage:
    python scripts/generate_transifex_batches.py --batch-size 5 --max-parallel 3

Generated output can be pasted directly into .github/workflows/sync_transifex.yml
"""

import argparse
import json
import math
from typing import List, Dict, Optional

# All supported locales (sorted alphabetically)
ALL_LOCALES = [
    "af_ZA", "am", "be", "bg", "bn", "ca", "cs", "da", "de", "el",
    "es", "et", "fi", "fr", "ga", "ha", "hi", "hr", "hu", "id",
    "is", "it", "ja", "jv", "kk", "km", "ko", "lt", "lv", "mk",
    "ms", "nl", "no", "pa", "pcm", "pl", "pt_BR", "pt_PT", "ro", "ru",
    "sk", "sl", "sq", "sr", "sv", "sw", "ta", "th", "tl", "tr",
    "vi", "yo", "zh-Hans", "zh-Hant"
]

# Priority tiers for future optimization
PRIORITY_TIERS = {
    "critical": ["fr", "ja", "ko", "zh-Hans", "zh-Hant"],  # Top 5 markets
    "important": ["de", "es", "it", "pt_BR", "ru", "vi", "zh-Hant"],  # Major markets
    "standard": []  # All others (auto-populated)
}

# Auto-populate standard tier
PRIORITY_TIERS["standard"] = [
    loc for loc in ALL_LOCALES
    if loc not in PRIORITY_TIERS["critical"] and loc not in PRIORITY_TIERS["important"]
]


def convert_locale_format(locale: str) -> str:
    """
    Convert internal locale format to Transifex format.

    Internal: pt_BR, zh-Hans (underscore for region)
    Transifex: pt-BR, zh-Hans (hyphen for region)
    """
    # Replace underscore with hyphen for Transifex compatibility
    return locale.replace("_", "-")


def generate_batches(batch_size: int, max_parallel: int, priority_based: bool = False, locales: Optional[List[str]] = None) -> List[Dict]:
    """
    Generate batch configuration for GitHub Actions matrix.

    Args:
        batch_size: Number of locales per batch
        max_parallel: Maximum parallel batches to run
        priority_based: If True, group by priority tiers
        locales: Optional list of specific locales to batch. If None, uses ALL_LOCALES.

    Returns:
        List of batch configurations
    """
    batches = []
    batch_id = 1

    # Use provided locales or default to all locales
    target_locales = locales if locales is not None else ALL_LOCALES

    if priority_based:
        # Group by priority tiers
        for tier in ["critical", "important", "standard"]:
            tier_locales = [loc for loc in PRIORITY_TIERS[tier] if loc in target_locales]

            for i in range(0, len(tier_locales), batch_size):
                batch_locales = tier_locales[i:i+batch_size]
                # Convert to Transifex format
                tx_locales = [convert_locale_format(loc) for loc in batch_locales]

                batches.append({
                    "id": batch_id,
                    "locales": ",".join(tx_locales),
                    "name": f"{tier}-{batch_id}",
                    "tier": tier
                })
                batch_id += 1
    else:
        # Simple sequential batching
        for i in range(0, len(target_locales), batch_size):
            batch_locales = target_locales[i:i+batch_size]
            # Convert to Transifex format
            tx_locales = [convert_locale_format(loc) for loc in batch_locales]

            batches.append({
                "id": batch_id,
                "locales": ",".join(tx_locales),
                "name": f"batch-{batch_id}"
            })
            batch_id += 1

    return batches


def print_github_actions_yaml(batches: List[Dict], max_parallel: int):
    """Print GitHub Actions matrix YAML configuration."""

    print("# Batch configuration for Transifex translation uploads")
    print("# Auto-generated by scripts/generate_transifex_batches.py")
    print("# DO NOT EDIT MANUALLY - Regenerate using the script")
    print()
    print("strategy:")
    print("  matrix:")
    print("    batch:")

    for batch in batches:
        if "tier" in batch:
            print(f"      - {{id: {batch['id']}, locales: \"{batch['locales']}\", name: \"{batch['name']}\", tier: \"{batch['tier']}\"}}")
        else:
            print(f"      - {{id: {batch['id']}, locales: \"{batch['locales']}\", name: \"{batch['name']}\"}}")

    print(f"  max-parallel: {max_parallel}")
    print("  fail-fast: false  # Don't cancel all jobs if one fails")


def print_github_actions_json(batches: List[Dict], resources_map: Optional[Dict[str, str]] = None) -> None:
    """
    Print GitHub Actions matrix JSON format.

    Output is compact JSON suitable for direct use in GitHub Actions matrix strategy.

    Args:
        batches: List of batch configurations
        resources_map: Optional mapping of locale -> resources (e.g., {"fr": "bisq2.chat,bisq2.user"})
    """
    matrix_items = []

    for batch in batches:
        item = {
            "id": batch["id"],
            "locales": batch["locales"],
            "name": batch["name"]
        }

        # Add resources if mapping provided
        if resources_map:
            # Collect unique resources for all locales in this batch
            batch_resource_set = set()
            batch_locale_list = batch["locales"].split(",")

            for tx_locale in batch_locale_list:
                # Convert Transifex format (pt-BR) back to internal format (pt_BR)
                internal_locale = tx_locale.replace("-", "_")

                if internal_locale in resources_map:
                    # Split comma-separated resources and add to set for deduplication
                    locale_resources = resources_map[internal_locale].split(",")
                    batch_resource_set.update(r.strip() for r in locale_resources if r.strip())

            # Sort for consistency and join back to comma-separated string
            item["resources"] = ",".join(sorted(batch_resource_set))

        matrix_items.append(item)

    matrix = {"include": matrix_items}

    # Compact JSON output (no extra whitespace)
    print(json.dumps(matrix, separators=(',', ':')))


def print_statistics(batches: List[Dict], max_parallel: int, batch_size: int, total_locales: int):
    """Print batch statistics and performance estimates."""

    total_batches = len(batches)
    parallel_rounds = math.ceil(total_batches / max_parallel)

    # Estimates
    upload_time_per_locale = 20  # seconds (average)
    delay_between_locales = 5   # seconds (rate limiting)
    batch_overhead = 30          # seconds (job setup)

    time_per_batch = (batch_size * upload_time_per_locale) + \
                     ((batch_size - 1) * delay_between_locales) + \
                     batch_overhead

    estimated_total_time = parallel_rounds * (time_per_batch / 60)  # minutes

    # API call calculations
    resources_per_locale = 17
    api_calls_per_batch = batch_size * resources_per_locale
    max_concurrent_calls = max_parallel * api_calls_per_batch

    print()
    print("=" * 70)
    print("BATCH CONFIGURATION STATISTICS")
    print("=" * 70)
    print()
    print(f"Total locales:          {total_locales}")
    print(f"Batch size:             {batch_size} locales per batch")
    print(f"Total batches:          {total_batches}")
    print(f"Max parallel batches:   {max_parallel}")
    print(f"Parallel rounds:        {parallel_rounds}")
    print()
    print("PERFORMANCE ESTIMATES")
    print("-" * 70)
    print(f"Time per batch:         ~{time_per_batch / 60:.1f} minutes")
    print(f"Total workflow time:    ~{estimated_total_time:.1f} minutes")
    print()
    print("API LOAD ANALYSIS")
    print("-" * 70)
    print(f"API calls per batch:    {api_calls_per_batch}")
    print(f"Max concurrent calls:   {max_concurrent_calls}")
    print(f"Rate limit safety:      {'✅ SAFE' if max_concurrent_calls < 180 else '⚠️ RISKY'}")
    print()

    # Comparison with PR #4013 failure
    failed_pr_calls = 476
    improvement = ((failed_pr_calls - max_concurrent_calls) / failed_pr_calls) * 100

    print("COMPARISON WITH PR #4013 FAILURE")
    print("-" * 70)
    print(f"Failed PR API calls:    {failed_pr_calls} concurrent")
    print(f"New config calls:       {max_concurrent_calls} concurrent")
    print(f"Reduction:              {improvement:.1f}%")
    print()

    # Recommendations
    print("RECOMMENDATIONS")
    print("-" * 70)
    if max_concurrent_calls > 180:
        print("⚠️  WARNING: API call volume still high - consider:")
        print("    - Reduce max-parallel to 2")
        print("    - Reduce batch-size to 4")
    elif max_concurrent_calls > 100:
        print("✅ ACCEPTABLE: API load manageable but monitor for rate limits")
    else:
        print("✅ EXCELLENT: API load well within safe limits")

    print()
    print("=" * 70)


def main():
    parser = argparse.ArgumentParser(
        description="Generate optimal batch configuration for Transifex uploads",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Standard batching (5 locales per batch, 3 parallel)
  python scripts/generate_transifex_batches.py --batch-size 5 --max-parallel 3

  # Priority-based batching (critical locales first)
  python scripts/generate_transifex_batches.py --batch-size 5 --max-parallel 3 --priority

  # Conservative batching (smaller batches, less parallelism)
  python scripts/generate_transifex_batches.py --batch-size 4 --max-parallel 2
        """
    )

    parser.add_argument(
        "--batch-size",
        type=int,
        default=5,
        help="Number of locales per batch (default: 5)"
    )

    parser.add_argument(
        "--max-parallel",
        type=int,
        default=3,
        help="Maximum number of parallel batches (default: 3)"
    )

    parser.add_argument(
        "--priority",
        action="store_true",
        help="Group batches by priority tiers (critical > important > standard)"
    )

    parser.add_argument(
        "--stats-only",
        action="store_true",
        help="Only print statistics without YAML output"
    )

    parser.add_argument(
        "--locales",
        type=str,
        help="Comma-separated list of locales to batch (e.g., 'fr,de,ja,ko'). Uses internal format (pt_BR). If omitted, uses all 54 locales."
    )

    parser.add_argument(
        "--json",
        action="store_true",
        help="Output GitHub Actions matrix JSON format instead of YAML (for dynamic workflow integration)"
    )

    parser.add_argument(
        "--resources-json",
        type=str,
        help="JSON string mapping locales to resources (e.g., '{\"fr\":\"bisq2.chat,bisq2.user\"}'). Used with --json to include resources in output."
    )

    args = parser.parse_args()

    # Validate inputs
    if args.batch_size < 1 or args.batch_size > 20:
        parser.error("batch-size must be between 1 and 20")

    if args.max_parallel < 1 or args.max_parallel > 10:
        parser.error("max-parallel must be between 1 and 10")

    # Parse locales if provided
    target_locales = None
    if args.locales:
        target_locales = [loc.strip() for loc in args.locales.split(',')]
        # Validate all provided locales are known
        invalid_locales = [loc for loc in target_locales if loc not in ALL_LOCALES]
        if invalid_locales:
            parser.error(f"Invalid locales: {', '.join(invalid_locales)}\nMust be one of: {', '.join(ALL_LOCALES)}")

    # Parse resources mapping if provided
    resources_map = None
    if args.resources_json:
        try:
            resources_map = json.loads(args.resources_json)
            if not isinstance(resources_map, dict):
                parser.error("--resources-json must be a valid JSON object")
        except json.JSONDecodeError as e:
            parser.error(f"Invalid JSON in --resources-json: {e}")

    # Generate batches
    batches = generate_batches(args.batch_size, args.max_parallel, args.priority, target_locales)

    # Determine total locales count for statistics
    total_locales = len(target_locales) if target_locales else len(ALL_LOCALES)

    # Print output
    if args.json:
        # JSON output only (no stats) for workflow integration
        print_github_actions_json(batches, resources_map)
    elif not args.stats_only:
        # YAML output with stats
        print_github_actions_yaml(batches, args.max_parallel)
        print_statistics(batches, args.max_parallel, args.batch_size, total_locales)
    else:
        # Stats only
        print_statistics(batches, args.max_parallel, args.batch_size, total_locales)


if __name__ == "__main__":
    main()
