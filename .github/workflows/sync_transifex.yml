name: Transifex

on:
  pull_request:
    types: [ opened, synchronize, reopened ]
    paths:
      - '.tx/config'
      - 'i18n/src/main/resources/**.properties'
  workflow_run:
    workflows: [ Build Bisq 2 ]
    types: [ completed ]

jobs:
  verify:
    name: Verify Transifex configuration
    if: github.event_name == 'pull_request' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout the repository
        uses: actions/checkout@v5
        with:
          ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.event.workflow_run.head_sha }}

      - name: Verify that .tx/config is in sync with the i18n folder
        run: |
          set -euo pipefail

          # Extract source files from .tx/config, trimming whitespace and de-duplicating
          config_files=$(grep -E '^[[:space:]]*source_file' .tx/config \
            | sed 's/.*= *//' \
            | sed 's|i18n/src/main/resources/||' \
            | sort -u)

          # Get actual source files from i18n directory (excluding locale-specific files)
          i18n_files=$(find i18n/src/main/resources -maxdepth 1 -name "*.properties" \
            | grep -v -E '(_[a-z]{2}(-[A-Z][a-z]+)?(([_-]([A-Z]{2}|[0-9]{3})))?|_pcm)\.properties$' \
            | sed 's|i18n/src/main/resources/||' \
            | sort -u)

          if [ "$config_files" != "$i18n_files" ]; then
            echo "::error::.tx/config is out of sync with i18n/src/main/resources/"
            echo "Please run the following command and commit the changes:"
            echo "./gradlew apps:desktop:i18n:updateTxConfig"
            diff -u <(echo "$config_files") <(echo "$i18n_files")
            exit 1
          fi
          echo ".tx/config is in sync with i18n/src/main/resources/"

  calculate_and_push_sources:
    name: Calculate pushes and push source files
    if: github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success'
    needs: verify
    runs-on: ubuntu-latest
    outputs:
      t_matrix: ${{ steps.calculate-pushes.outputs.t_matrix || '{"include":[]}' }}
      has_translation_changes: ${{ steps.calculate-pushes.outputs.has_translation_changes }}
    steps:
      - name: Checkout the repository
        uses: actions/checkout@v5
        with:
          ref: ${{ github.event.workflow_run.head_sha }}
          fetch-depth: 0

      - name: Check if the commit is in the main branch
        id: check_commit
        run: |
          git fetch origin main
          if git merge-base --is-ancestor ${{ github.event.workflow_run.head_sha }} origin/main; then
            echo "commit_in_main=true" >> $GITHUB_OUTPUT
          else
            echo "commit_in_main=false" >> $GITHUB_OUTPUT
          fi

      - name: "Check if TX_TOKEN secret exists"
        if: steps.check_commit.outputs.commit_in_main == 'true'
        env:
          transifex_secret: ${{ secrets.TX_TOKEN }}
        run: |
          if [ -z "$transifex_secret" ]; then
            echo "The secret \"TX_TOKEN\" has not been set; please go to \"settings > secrets and variables\" to create it"
            exit 1
          fi

      - name: Calculate push commands
        id: calculate-pushes
        if: steps.check_commit.outputs.commit_in_main == 'true'
        run: |
          set -euo pipefail

          echo "Finding changed files..."
          # We compare the merge commit with its first parent to get the list of files.
          # Note: This is reliable for standard PR merges but may not handle octopus merges.
          CHANGED_FILES=$(git diff --name-only ${{ github.event.workflow_run.head_sha }}~1 ${{ github.event.workflow_run.head_sha }})
          echo "Files changed in the merge:"
          echo "$CHANGED_FILES"

          # --- Handle SOURCE file pushes (-s) ---
          s_args=""
          if echo "${CHANGED_FILES}" | grep -q -x ".tx/config"; then
            echo "::notice:: .tx/config changed. Pushing all source files."
            s_args="push -s"
          else
            s_resources="" # This will be the comma-separated list
            CHANGED_SOURCE_FILES=$(echo "${CHANGED_FILES}" | grep -E '\.properties$' | grep -v -E '(_[a-z]{2}(-[A-Z][a-z]+)?(([_-]([A-Z]{2}|[0-9]{3})))?|_pcm)\.properties$' -- || true)
            if [ -n "$CHANGED_SOURCE_FILES" ]; then
              for file in $CHANGED_SOURCE_FILES; do
                resource_slug_line=$(awk -v file="$file" '
                  $0 ~ /^\[o:.*:p:.*:r:.*\]$/ {resource=$0}
                  $0 ~ ("source_file[[:space:]]*=[[:space:]]*" file "$") {print resource}
                ' .tx/config)
                if [[ -n "$resource_slug_line" ]] && [[ "$resource_slug_line" =~ ^\[o:.*:p:(.*):r:(.*)\]$ ]]; then
                  project_slug="${BASH_REMATCH[1]}"
                  resource_slug="${BASH_REMATCH[2]}"
                  full_resource_id="${project_slug}.${resource_slug}"
                  if [[ -z "$s_resources" ]]; then
                      s_resources="$full_resource_id"
                  else
                      s_resources+=",$full_resource_id"
                  fi
                else
                  echo "::warning::Could not find resource slug for changed source file: $file"
                fi
              done
            fi
            # If we found any resources, construct the final args string
            if [[ -n "$s_resources" ]]; then
              s_args="push -s -r $s_resources"
            fi
          fi
          echo "s_args=$s_args" >> $GITHUB_OUTPUT

          # --- Handle TRANSLATION file pushes (-t) with BATCHING ---
          # Collect all changed locales and their resources
          declare -A lang_resources
          CHANGED_TRANSLATION_FILES=$(echo "${CHANGED_FILES}" | grep -E 'i18n/src/main/resources/.*\.properties$' | grep -E '(_[a-z]{2}(-[A-Z][a-z]+)?(([_-]([A-Z]{2}|[0-9]{3})))?|_pcm)\.properties$' -- || true)

          if [ -n "$CHANGED_TRANSLATION_FILES" ]; then
            echo "has_translation_changes=true" >> $GITHUB_OUTPUT

            for file in $CHANGED_TRANSLATION_FILES; do
              lang=$(echo "$file" | sed -E 's/.*_([a-z]{2}(-[A-Z][a-z]+)?(([_-]([A-Z]{2}|[0-9]{3})))?|pcm)\.properties$/\1/')
              resource_slug_line=$(awk -v file="$file" -v lang="$lang" '
                BEGIN{FS="="}
                $0 ~ /^\[o:.*:p:.*:r:.*\]$/ {resource=$0}
                $1 ~ /^[[:space:]]*file_filter/ {
                    filter_path=$2;
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", filter_path);
                    gsub(/<lang>/, lang, filter_path);
                    if (filter_path == file) {
                        print resource;
                        exit;
                    }
                }
              ' .tx/config)
              if [[ -n "$resource_slug_line" ]] && [[ "$resource_slug_line" =~ ^\[o:.*:p:(.*):r:(.*)\]$ ]]; then
                project_slug="${BASH_REMATCH[1]}"
                resource_slug="${BASH_REMATCH[2]}"
                full_resource_id="${project_slug}.${resource_slug}"
                if [[ ! -v lang_resources[$lang] ]]; then
                    lang_resources[$lang]="$full_resource_id"
                else
                    lang_resources[$lang]+=",$full_resource_id"
                fi
              fi
            done

            # Generate batched matrix configuration dynamically
            # Uses Python script to create optimal batches based on changed locales only

            # Collect changed locales into comma-separated list
            changed_locales_list=""
            for locale in "${!lang_resources[@]}"; do
              changed_locales_list="${changed_locales_list:+$changed_locales_list,}$locale"
            done

            if [ -n "$changed_locales_list" ]; then
              echo "::notice::Changed locales: $changed_locales_list"

              # Generate batch configuration dynamically using Python script
              # This creates batches only for locales that actually changed
              batch_matrix=$(python3 scripts/generate_transifex_batches.py \
                --locales "$changed_locales_list" \
                --batch-size 4 \
                --max-parallel 2 \
                --json)

              echo "::notice::Generated batch configuration: $batch_matrix"

              # Now enhance with resource information for each batch
              # Parse the JSON and add resources field
              json_output='{"include":['
              first_batch=true

              # Extract batches from JSON using jq-like parsing (pure bash)
              # Read batch info from Python output
              batch_count=$(echo "$batch_matrix" | grep -o '"id":[0-9]*' | wc -l)

              for ((batch_idx=0; batch_idx<batch_count; batch_idx++)); do
                # Extract locales for this batch
                batch_locales=$(echo "$batch_matrix" | python3 -c "
import sys, json
data = json.load(sys.stdin)
print(data['include'][$batch_idx]['locales'])
")

                batch_id=$(echo "$batch_matrix" | python3 -c "
import sys, json
data = json.load(sys.stdin)
print(data['include'][$batch_idx]['id'])
")

                batch_name=$(echo "$batch_matrix" | python3 -c "
import sys, json
data = json.load(sys.stdin)
print(data['include'][$batch_idx]['name'])
")

                # Build resources list for this batch's locales
                batch_resources=""
                IFS=',' read -ra LOCALES <<< "$batch_locales"
                for locale in "${LOCALES[@]}"; do
                  # Convert Transifex format (pt-BR) to internal format (pt_BR)
                  internal_locale=$(echo "$locale" | sed 's/-/_/g')

                  if [[ -v lang_resources[$internal_locale] ]]; then
                    if [ -z "$batch_resources" ]; then
                      batch_resources="${lang_resources[$internal_locale]}"
                    else
                      # Merge resources (deduplicate by splitting and rejoining)
                      batch_resources="$batch_resources,${lang_resources[$internal_locale]}"
                    fi
                  fi
                done

                # Add batch to output
                if ! $first_batch; then
                  json_output+=','
                fi
                json_output+="{\"id\":$batch_id,\"locales\":\"$batch_locales\",\"resources\":\"$batch_resources\",\"name\":\"$batch_name\"}"
                first_batch=false
              done

              json_output+=']}'
              printf 't_matrix=%s\n' "$json_output" >> "$GITHUB_OUTPUT"
            else
              # No changed locales
              echo 't_matrix={"include":[]}' >> "$GITHUB_OUTPUT"
            fi
          else
            echo "has_translation_changes=false" >> $GITHUB_OUTPUT
            echo 't_matrix={"include":[]}' >> "$GITHUB_OUTPUT"
          fi

      - name: Push source files to Transifex
        if: steps.calculate-pushes.outputs.s_args != ''
        uses: transifex/cli-action@v2
        with:
          token: ${{ secrets.TX_TOKEN }}
          args: ${{ steps.calculate-pushes.outputs.s_args }}

  push_translations:
    name: Push translations (${{ matrix.name }})
    if: needs.calculate_and_push_sources.outputs.t_matrix != '{"include":[]}'
    needs: calculate_and_push_sources
    runs-on: ubuntu-latest
    # PHASE 1: Dynamic batching with controlled parallelism
    # Batches are generated dynamically based on changed locales only
    # Uses scripts/generate_transifex_batches.py for optimal batch configuration
    strategy:
      matrix: ${{ fromJson(needs.calculate_and_push_sources.outputs.t_matrix) }}
      max-parallel: 2  # Only 2 batches at a time (136 max concurrent API calls)
      fail-fast: false  # Don't cancel all jobs if one fails
    steps:
      - name: Checkout the repository
        uses: actions/checkout@v5
        with:
          ref: ${{ github.event.workflow_run.head_sha }}

      # PHASE 1: Stagger batch starts to prevent API overload
      - name: Stagger batch start
        run: |
          # Add delay based on batch ID to prevent simultaneous starts
          DELAY=$(((${{ matrix.id }} - 1) * 10))
          echo "::notice::Delaying batch ${{ matrix.id }} by ${DELAY}s for rate limiting"
          sleep $DELAY

      # PHASE 1: Retry logic with exponential backoff
      - name: Push ${{ matrix.name }} translations with retry
        uses: nick-fields/retry@v3
        id: push_with_retry
        with:
          timeout_minutes: 10
          max_attempts: 3
          retry_wait_seconds: 15
          exponential_backoff: true
          retry_on: error
          command: |
            set -euo pipefail

            echo "::group::Uploading translations for batch: ${{ matrix.locales }}"

            # Split batch locales and upload with inter-locale delay
            IFS=',' read -ra LOCALES <<< "${{ matrix.locales }}"
            UPLOADED_COUNT=0

            for locale in "${LOCALES[@]}"; do
              echo "::notice::Uploading locale: $locale"

              # Rate limiting: 5s delay between locales within batch
              if [ $UPLOADED_COUNT -gt 0 ]; then
                echo "::notice::Rate limiting: sleeping 5s between locales"
                sleep 5
              fi

              # Capture full output for error diagnosis
              OUTPUT=$(tx push -t -l $locale -r "${{ matrix.resources }}" 2>&1) || EXIT_CODE=$?

              if [ ${EXIT_CODE:-0} -ne 0 ]; then
                echo "$OUTPUT"

                # Distinguish permanent vs transient errors
                if echo "$OUTPUT" | grep -qi "unauthorized\|forbidden\|not found\|invalid"; then
                  echo "::error::Permanent error for $locale - no retry"
                  echo "::error::$OUTPUT"
                  exit 1  # Don't retry permanent errors
                elif echo "$OUTPUT" | grep -qi "timeout\|rate limit\|too many requests\|connection\|network"; then
                  echo "::warning::Transient error for $locale - will retry"
                  echo "::warning::$OUTPUT"
                  exit 2  # Retry transient errors
                else
                  echo "::warning::Unknown error for $locale - will retry once"
                  echo "::warning::$OUTPUT"
                  exit 2
                fi
              fi

              echo "âœ… Upload successful: $locale"
              ((UPLOADED_COUNT++))
            done

            echo "::endgroup::"
            echo "::notice::Batch ${{ matrix.name }} complete: ${UPLOADED_COUNT} locales uploaded"

      # PHASE 1: Upload verification
      - name: Verify upload succeeded
        if: steps.push_with_retry.outcome == 'success'
        run: |
          echo "::group::Verifying uploads for batch: ${{ matrix.locales }}"

          IFS=',' read -ra LOCALES <<< "${{ matrix.locales }}"
          VERIFICATION_FAILED=false

          for locale in "${LOCALES[@]}"; do
            echo "Verifying $locale..."

            # Pull back what we just pushed (dry-run to avoid downloading)
            if ! tx pull -l $locale -r "${{ matrix.resources }}" --mode onlytranslated --dry-run 2>&1 | grep -q "Pulling"; then
              echo "::warning::Verification FAILED for $locale - not found in Transifex"
              VERIFICATION_FAILED=true
            else
              echo "âœ… Verified: $locale exists in Transifex"
            fi
          done

          echo "::endgroup::"

          if [ "$VERIFICATION_FAILED" = true ]; then
            echo "::error::Some translations failed verification"
            echo "::error::Uploaded files may not be in Transifex - manual investigation required"
            exit 1
          fi

      # Report metrics for monitoring
      - name: Report upload metrics
        if: always()
        run: |
          echo "## ðŸŒ Batch ${{ matrix.name }} Upload Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Batch ID**: ${{ matrix.id }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Locales**: ${{ matrix.locales }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ steps.push_with_retry.outcome }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Verification**: ${{ steps.verify.outcome || 'skipped' }}" >> $GITHUB_STEP_SUMMARY

  # Summary job to aggregate results
  summary:
    name: Upload Summary Report
    needs: [calculate_and_push_sources, push_translations]
    if: always() && needs.calculate_and_push_sources.outputs.has_translation_changes == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Generate summary
        run: |
          echo "# ðŸŒ Translation Upload Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Note: In GitHub Actions, we can't easily aggregate matrix job results
          # This is a placeholder for future monitoring enhancements
          echo "Translation upload workflow completed." >> $GITHUB_STEP_SUMMARY
          echo "Check individual batch job logs for detailed status." >> $GITHUB_STEP_SUMMARY
